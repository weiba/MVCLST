{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we load the packages required for running the modified code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from get_data import run\n",
    "import scanpy as sc\n",
    "from sklearn import metrics\n",
    "from scipy.spatial import distance\n",
    "from utils import *\n",
    "from torch_geometric.nn import HypergraphConv\n",
    "from MVCLST import train\n",
    "import anndata\n",
    "from scipy.stats import zscore\n",
    "from utils_copy import clustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from augment import *\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set the data we are about to process. Here, we set the data as 151673 from the DLPFC dataset, as well as the output folder address after running the data, and some values that need to be pre-set in advance, such as the number of clusters in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['151673']\n",
    "for sample in sample_list:\n",
    "    data_path = \"./data/151673\" \n",
    "    data_name = sample\n",
    "    save_path = data_path+\"/\"+sample+\"/\"+'chebyshev'+str(i) #### save path\n",
    "    save_path_figure = Path(os.path.join(save_path, \"Figure\", data_name))\n",
    "    save_path_figure.mkdir(parents=True, exist_ok=True)\n",
    "    if data_name in ['151669','151670','151671','151672']:\n",
    "        n_domains = 5\n",
    "    else:\n",
    "        n_domains = 6\n",
    "    data = run(save_path = save_path, \n",
    "        platform = \"Visium\",\n",
    "        pca_n_comps = 128,\n",
    "        pre_epochs = 800,\n",
    "        vit_type='vit_b',#'vit'\n",
    "        )\n",
    "    if sample==\"151671\":\n",
    "        i=6\t\n",
    "    else:\n",
    "        i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read our data labels and data here, where we use _get-data to read the data we need and process it into the appropriate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(data_path+'/'+data_name+'/metadata.tsv', sep='\\t')\n",
    "adata =data._get_adata(data_path, data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = data._get_augment(adata, adjacent_weight = 1, neighbour_k =6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preparation and screening of data are referred to as our data preprocessing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1=adata.copy()\n",
    "adata.X = adata.obsm[\"augment_gene_data\"].astype(float)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "adata_X = sc.pp.normalize_total(adata, target_sum=1, exclude_highly_expressed=True, inplace=False)['X']\n",
    "adata_X = sc.pp.log1p(adata_X)\n",
    "adata_X = sc.pp.scale(adata_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform dimensionality reduction on the data here, which will be used in the subsequent pre clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = sc.pp.pca(adata_X, n_comps=128)\n",
    "inputs = sc.pp.pca(adata_X, n_comps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre clustering, where we process the pre clustered data, including transforming it into a graph structure and masking the neighbor relationships in the pre clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label,_=cluster(adata,inputs1,df_meta,n_domains)\n",
    "cluster_adj=create_adjacency_matrix(cluster_label)\n",
    "adj_augment = adata.obsm[\"weights_matrix_all\"]\n",
    "adj_augment=sim2adj(adj_augment,6)\n",
    "adj_pure=sim2adj(adata.obsm[\"weights_matrix_nomd\"],6)\n",
    "adj_pure=cluster_adj*adj_pure\n",
    "adata1.obsm['weights_matrix_all']=adj_pure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation here includes determining the neighbor relationships of the second view generated by masking the neighbor relationships through pre clustering, and enhancing the original data through the neighbor relationships of the second view to generate the expression data of the second view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1=find_adjacent_spot(\n",
    "adata1,\n",
    "use_data = \"raw\",\n",
    "neighbour_k = 6,\n",
    "weights='weights_matrix_all',\n",
    "verbose = False,\n",
    ")\n",
    "adata1=augment_gene_data(\n",
    "adata1,\n",
    "use_data = \"raw\",\n",
    "adjacent_weight = 1,\n",
    ")\n",
    "adata1.X = adata1.obsm[\"augment_gene_data\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data from the second view, reduce the dimensionality of the preprocessed data, and convert it with the data from the previous first view to prepare the data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1_X = sc.pp.normalize_total(adata1, target_sum=1, exclude_highly_expressed=True, inplace=False)['X']\n",
    "adata1_X = sc.pp.log1p(adata1_X)\n",
    "adata1_X = sc.pp.scale(adata1_X)\n",
    "inputs2 = sc.pp.pca(adata1_X, n_comps=1000)\n",
    "X=inputs.copy()\n",
    "X2=inputs2.copy()\n",
    "X=torch.tensor(X,dtype=torch.float)\n",
    "X2=torch.tensor(X2,dtype=torch.float)\n",
    "adj_pure = adata.obsm[\"weights_matrix_nomd\"]\n",
    "adj_pure = cluster_adj*adj_pure\n",
    "adj_pure =sim2adj(adj_pure ,6)\n",
    "adj_augment=torch.tensor(adj_augment,dtype=torch.float)\n",
    "adj_pure=torch.tensor(adj_pure,dtype=torch.float)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the prepared data into the model for training, including adata data, enhanced gene expression data and neighbor structure from the first view, and enhanced gene expression data and neighbor structure from the second view. Label data is only sent here to monitor the feature extraction during the data learning process. And cluster number data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features=train(adata,X,X2,adj_pure,adj_augment,df_meta,n_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the features extracted by the trained model for the next clustering operation and generate spatial domain partition images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ARI=cluster(adata,best_features,df_meta,n_domains,refined=True)\n",
    "data.plot_domains(adata, data_name)\n",
    "print(adata)\n",
    "adata.write(os.path.join(save_path, f'{data_name}.h5ad'),compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
